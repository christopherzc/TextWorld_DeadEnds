_current_progress_remaining:
    value: 1
_custom_logger:
    value: "False"
_episode_num:
    value: 0
_last_episode_starts:
    value: '[ True]'
_last_obs:
    value: |-
        [[ 10  10  10  10  10  10  45  61  32  83 116 114  97 110 103 101  32  83
          113 117  97 114 101  32  61  45  10  89 111 117  39 114 101  32 110 111
          119  32 105 110  32 116 104 101  32 115 116 114  97 110 103 101  32 115
          113 117  97 114 101  46  10  10  10  10  84 104 101 114 101  32 105 115
           32  97 110  32 117 110 103 117  97 114 100 101 100  32 101 120 105 116
           32 116 111  32 116 104 101  32 110 111 114 116 104  46  32  89 111 117
           32 110 101 101 100  32  97 110  32 117 110  98 108 111  99 107 101 100
           32 101 120 105 116  63  32  89 111 117  32 115 104 111 117 108 100  32
          116 114 121  32 103 111 105 110 103  32 115 111 117 116 104  46  32  84
          104 101 114 101  32 105 115  32  97 110  32 117 110  98 108 111  99 107
          101 100  32 101 120 105 116  32 116 111  32 116 104 101  32 119 101 115
          116  46  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
            0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
            0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
            0   0   0   0]]
_last_original_obs:
    value: None
_logger:
    value: <stable_baselines3.common.logger.Logger object at 0x148d24a03fe0>
_n_updates:
    value: 0
_num_timesteps_at_start:
    value: 0
_stats_window_size:
    value: 100
_total_timesteps:
    value: 1000000
_vec_normalize_env:
    value: None
_wandb:
    value:
        cli_version: 0.20.1
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 16
                - 22
                - 35
                - 55
            "4": 3.12.11
            "5": 0.20.1
            "12": 0.20.1
            "13": linux-x86_64
action_noise:
    value: None
action_space:
    value: Discrete(4)
algo:
    value: PPO
batch_size:
    value: 64
clip_range:
    value: <function get_schedule_fn.<locals>.<lambda> at 0x148d24be45e0>
clip_range_vf:
    value: None
device:
    value: cpu
ent_coef:
    value: 0
env:
    value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x148c475b6870>
ep_info_buffer:
    value: deque([], maxlen=100)
ep_success_buffer:
    value: deque([], maxlen=100)
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
learning_rate:
    value: 0.0003
lr_schedule:
    value: <function get_schedule_fn.<locals>.<lambda> at 0x148c473a0860>
max_grad_norm:
    value: 0.5
max_steps_per_episode:
    value: 50
n_envs:
    value: 1
n_epochs:
    value: 10
n_steps:
    value: 2048
normalize_advantage:
    value: "True"
num_timesteps:
    value: 0
observation_space:
    value: Box(0, 255, (256,), uint8)
policy:
    value: |-
        ActorCriticPolicy(
          (features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (pi_features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (vf_features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (mlp_extractor): MlpExtractor(
            (policy_net): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): Tanh()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Tanh()
            )
            (value_net): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): Tanh()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Tanh()
            )
          )
          (action_net): Linear(in_features=64, out_features=4, bias=True)
          (value_net): Linear(in_features=64, out_features=1, bias=True)
        )
policy_class:
    value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
policy_kwargs:
    value: '{}'
rollout_buffer:
    value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x148c475b50d0>
rollout_buffer_class:
    value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
    value: '{}'
sde_sample_freq:
    value: -1
seed:
    value: None
start_time:
    value: 1750888258575572203
target_kl:
    value: None
tensorboard_log:
    value: ./tb_logs/
total_timesteps:
    value: 1000000
use_sde:
    value: "False"
verbose:
    value: 1
vf_coef:
    value: 0.5

_current_progress_remaining:
    value: 1
_custom_logger:
    value: "False"
_episode_num:
    value: 0
_last_episode_starts:
    value: '[ True]'
_last_obs:
    value: |-
        [[ 10  10  10  10  10  10  45  61  32  82 101 100  32  83 112 105 114  97
          108  32  61  45  10  89 111 117  32  97 114 101  32 105 110  32  97  32
          114 101 100  32 115 112 105 114  97 108  46  32  65 110  32 117 115 117
           97 108  32 111 110 101  46  32  89 111 117  32 100 101  99 105 100 101
           32 116 111  32 115 116  97 114 116  32 108 105 115 116 105 110 103  32
          111 102 102  32 101 118 101 114 121 116 104 105 110 103  32 121 111 117
           32 115 101 101  32 105 110  32 116 104 101  32 114 111 111 109  44  32
           97 115  32 105 102  32 121 111 117  32 119 101 114 101  32 105 110  32
           97  32 116 101 120 116  32  97 100 118 101 110 116 117 114 101  46  10
           10  10  10  89 111 117  32 110 101 101 100  32  97 110  32 117 110  98
          108 111  99 107 101 100  32 101 120 105 116  63  32  89 111 117  32 115
          104 111 117 108 100  32 116 114 121  32 103 111 105 110 103  32 110 111
          114 116 104  46  32  84 104 101 114 101  32 105 115  32  97 110  32 101
          120 105 116  32 116 111  32 116 104 101  32 115 111 117 116 104  46  32
           68 111 110  39]]
_last_original_obs:
    value: None
_logger:
    value: <stable_baselines3.common.logger.Logger object at 0x14b662bfac60>
_n_updates:
    value: 0
_num_timesteps_at_start:
    value: 0
_stats_window_size:
    value: 100
_total_timesteps:
    value: 1000000
_vec_normalize_env:
    value: None
_wandb:
    value:
        cli_version: 0.20.1
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 16
                - 22
                - 35
                - 55
            "4": 3.12.11
            "5": 0.20.1
            "12": 0.20.1
            "13": linux-x86_64
action_noise:
    value: None
action_space:
    value: Discrete(4)
algo:
    value: PPO
batch_size:
    value: 64
clip_range:
    value: <function get_schedule_fn.<locals>.<lambda> at 0x14b662bd82c0>
clip_range_vf:
    value: None
device:
    value: cpu
ent_coef:
    value: 0
env:
    value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x14b58a3c27b0>
ep_info_buffer:
    value: deque([], maxlen=100)
ep_success_buffer:
    value: deque([], maxlen=100)
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
learning_rate:
    value: 0.0003
lr_schedule:
    value: <function get_schedule_fn.<locals>.<lambda> at 0x14b5894b0f40>
max_grad_norm:
    value: 0.5
max_steps_per_episode:
    value: 50
n_envs:
    value: 1
n_epochs:
    value: 10
n_steps:
    value: 2048
normalize_advantage:
    value: "True"
num_timesteps:
    value: 0
observation_space:
    value: Box(0, 255, (256,), uint8)
policy:
    value: |-
        ActorCriticPolicy(
          (features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (pi_features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (vf_features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (mlp_extractor): MlpExtractor(
            (policy_net): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): Tanh()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Tanh()
            )
            (value_net): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): Tanh()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Tanh()
            )
          )
          (action_net): Linear(in_features=64, out_features=4, bias=True)
          (value_net): Linear(in_features=64, out_features=1, bias=True)
        )
policy_class:
    value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
policy_kwargs:
    value: '{}'
rollout_buffer:
    value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x14b58a1364b0>
rollout_buffer_class:
    value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
    value: '{}'
sde_sample_freq:
    value: -1
seed:
    value: None
start_time:
    value: 1750888638894470134
target_kl:
    value: None
tensorboard_log:
    value: ./tb_logs/
total_timesteps:
    value: 1000000
use_sde:
    value: "False"
verbose:
    value: 1
vf_coef:
    value: 0.5
